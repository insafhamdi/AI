{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb04fa67",
      "metadata": {
        "id": "bb04fa67"
      },
      "source": [
        "  \n",
        "  \n",
        "   # Chapter 3- PART I: Text preprocessing for NLP\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/7065401/55025843-7d99a280-4fe0-11e9-938a-4879d95c4130.png\"\n",
        "    style=\"width:150px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
        "    \n",
        "<img src=\"https://www.searchenginejournal.com/wp-content/uploads/2020/08/an-introduction-to-natural-language-processing-with-python-for-seos-5f3519eeb8368-1520x800.webp\" style=\"width:300px; float: left; margin: 0 40px 40px 40px;\"></img>\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c00f4de",
      "metadata": {
        "id": "5c00f4de"
      },
      "source": [
        "# Part I: Standard preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe54897",
      "metadata": {
        "id": "afe54897"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1d6b3a",
      "metadata": {
        "id": "7c1d6b3a",
        "outputId": "8b67de34-7f53-4099-f9f6-033d256dd31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# download datasets and resources for NLP\n",
        "nltk.download(\"book\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3efd095",
      "metadata": {
        "id": "c3efd095",
        "outputId": "6dc166e4-03f9-4166-dabe-ed3ab9724661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Sense and Sensibility by Jane Austen 1811>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Task : import a book from the database\n",
        "from nltk.book import text2\n",
        "text2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f0908a",
      "metadata": {
        "id": "c0f0908a"
      },
      "source": [
        "# 1- Basic Operations on Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66697561",
      "metadata": {
        "id": "66697561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ed8501-f905-4b1e-b687-398c217b7f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141576"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# get the length of the book (the number of words in the book)\n",
        "len(text2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf829998",
      "metadata": {
        "id": "cf829998",
        "outputId": "99011323-72fa-42c4-c540-10f886a1f670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6833"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# set() eliminate duplicates\n",
        "set(text2)\n",
        "# gives the length of unique words\n",
        "len(set(text2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34d168f",
      "metadata": {
        "id": "f34d168f",
        "outputId": "3574cb43-7ad8-4b95-e448-dfedebb0ed83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "684"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# count()\n",
        "#Example\n",
        "#1- display text\n",
        "text2\n",
        "#2- How many times is the word \"the\" present in the text\n",
        "text2.count('the')\n",
        "\n",
        "#3- Case sensitive ?\n",
        "text2.count('Elinor')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81abb8af",
      "metadata": {
        "id": "81abb8af"
      },
      "outputs": [],
      "source": [
        "# freq distribution\n",
        "# import class FreqDist\n",
        "from nltk import FreqDist\n",
        "\n",
        "# example: get the frequency distribution for all the words\n",
        "\n",
        "fd= FreqDist(text2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f2a965",
      "metadata": {
        "id": "08f2a965",
        "outputId": "56eee895-5a83-4595-fdb8-f91f205c6341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 9397),\n",
              " ('to', 4063),\n",
              " ('.', 3975),\n",
              " ('the', 3861),\n",
              " ('of', 3565),\n",
              " ('and', 3350),\n",
              " ('her', 2436),\n",
              " ('a', 2043),\n",
              " ('I', 2004),\n",
              " ('in', 1904)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# find the most common 10 words in the book\n",
        "fd.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9a64fe",
      "metadata": {
        "id": "df9a64fe",
        "outputId": "48a0762b-946c-497e-dab4-0f9b3eb1b8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ,   to    .  the   of  and  her    a    I   in \n",
            "9397 4063 3975 3861 3565 3350 2436 2043 2004 1904 \n"
          ]
        }
      ],
      "source": [
        "#display the frequency distribution of words or tokens in a more readable tabular format\n",
        "#plus organisé dans un tableau\n",
        "fd.tabulate(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fbfb83a",
      "metadata": {
        "id": "4fbfb83a",
        "outputId": "6a73302f-0706-49ed-af47-16ef6b4d5344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02366220263321467"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# find the frequency of one particular word of your choice\n",
        "fd.freq('and')\n",
        "# This value represents the proportion of times the word 'and' appears relative to the total number of words in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97eecd4",
      "metadata": {
        "scrolled": true,
        "id": "b97eecd4",
        "outputId": "f2176753-65da-4896-dc87-98d03949fd37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3350"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#get the count\n",
        "fd['and']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adae809f",
      "metadata": {
        "id": "adae809f"
      },
      "outputs": [],
      "source": [
        "example_text = \"Amidst the bustling city streets, a lone traveler embarked on a journey of self-discovery. The sun painted the sky with hues of orange and pink as birds sang melodious tunes overhead. With each step, the traveler encountered new faces and stories, weaving a tapestry of experiences that would shape their destiny. As night fell, he found shelter under a starry canopy, dreaming of adventures yet to come.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76b5f09",
      "metadata": {
        "scrolled": true,
        "id": "c76b5f09",
        "outputId": "74f7cf3b-06d6-4a9b-cce7-0af145f3b3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# get the type\n",
        "type(example_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a981bdce",
      "metadata": {
        "id": "a981bdce",
        "outputId": "c2e6b9c9-5f9b-4ada-846d-321a111b20a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.text.Text</b><br/>def __init__(tokens, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/text.py</a>A wrapper around a sequence of simple (string) tokens, which is\n",
              "intended to support initial exploration of texts (via the\n",
              "interactive console).  Its methods perform a variety of analyses\n",
              "on the text&#x27;s contexts (e.g., counting, concordancing, collocation\n",
              "discovery), and display the results.  If you wish to write a\n",
              "program which makes use of these analyses, then you should bypass\n",
              "the ``Text`` class, and use the appropriate analysis function or\n",
              "class directly instead.\n",
              "\n",
              "A ``Text`` is typically initialized from a given document or\n",
              "corpus.  E.g.:\n",
              "\n",
              "&gt;&gt;&gt; import nltk.corpus\n",
              "&gt;&gt;&gt; from nltk.text import Text\n",
              "&gt;&gt;&gt; moby = Text(nltk.corpus.gutenberg.words(&#x27;melville-moby_dick.txt&#x27;))</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 308);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#get the type of text2\n",
        "type(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101b73ce",
      "metadata": {
        "id": "101b73ce"
      },
      "outputs": [],
      "source": [
        "# nltk.text.text for analyzing and manipulating text corpora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c870b16f",
      "metadata": {
        "id": "c870b16f"
      },
      "outputs": [],
      "source": [
        "# Task: convert str to nltk.text\n",
        "#NB: we will use nltk.Text that requires its input to be a list of tokens, not a single string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "954dbad4",
      "metadata": {
        "id": "954dbad4"
      },
      "outputs": [],
      "source": [
        "new_text=nltk.Text(example_text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f9f89c",
      "metadata": {
        "id": "b3f9f89c",
        "outputId": "39c9e1ac-8593-478b-f93c-95baa986bdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.text.Text</b><br/>def __init__(tokens, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/text.py</a>A wrapper around a sequence of simple (string) tokens, which is\n",
              "intended to support initial exploration of texts (via the\n",
              "interactive console).  Its methods perform a variety of analyses\n",
              "on the text&#x27;s contexts (e.g., counting, concordancing, collocation\n",
              "discovery), and display the results.  If you wish to write a\n",
              "program which makes use of these analyses, then you should bypass\n",
              "the ``Text`` class, and use the appropriate analysis function or\n",
              "class directly instead.\n",
              "\n",
              "A ``Text`` is typically initialized from a given document or\n",
              "corpus.  E.g.:\n",
              "\n",
              "&gt;&gt;&gt; import nltk.corpus\n",
              "&gt;&gt;&gt; from nltk.text import Text\n",
              "&gt;&gt;&gt; moby = Text(nltk.corpus.gutenberg.words(&#x27;melville-moby_dick.txt&#x27;))</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 308);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "type(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd_1= FreqDist(new_text)\n",
        "fd_1.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J56vuo8XyGmH",
        "outputId": "31206376-588c-43ac-df05-b801e2d409ba"
      },
      "id": "J56vuo8XyGmH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 4),\n",
              " ('of', 4),\n",
              " ('the', 3),\n",
              " ('traveler', 2),\n",
              " ('and', 2),\n",
              " ('Amidst', 1),\n",
              " ('bustling', 1),\n",
              " ('city', 1),\n",
              " ('streets,', 1),\n",
              " ('lone', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa37410a",
      "metadata": {
        "scrolled": true,
        "id": "fa37410a",
        "outputId": "6d69c299-0530-4462-889a-4d3710c28184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Samples', ylabel='Counts'>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#Task: visualize the most frequent words in a text, based on their frequency distribution\n",
        "fd_1.plot(10) #10 le nbre de mots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e87622a",
      "metadata": {
        "id": "6e87622a"
      },
      "source": [
        "# 2- Text Preprocessing techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aad8972e",
      "metadata": {
        "id": "aad8972e"
      },
      "source": [
        "## 2-1 Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77640305",
      "metadata": {
        "id": "77640305",
        "outputId": "d3f69049-c903-444d-abe5-b8b00c4eacdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is an example text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# lowercasing\n",
        "txt = \"This IS an example TEXT\"\n",
        "txt.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d4497d",
      "metadata": {
        "id": "96d4497d"
      },
      "source": [
        "## 2-2 Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a91a6c1",
      "metadata": {
        "id": "3a91a6c1"
      },
      "source": [
        "Tokenization is the process of breaking down a text or a sequence of characters into smaller units called **tokens**.\n",
        "\n",
        "Tokens are the basic building blocks of text and can be individual words, punctuation marks, or other meaningful elements, depending on the specific task and language.\n",
        "\n",
        "Tokenization is a fundamental step in NLP and text analysis because it enables a computer to understand and process human language."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6fce40",
      "metadata": {
        "id": "4f6fce40"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5f8a562",
      "metadata": {
        "id": "d5f8a562"
      },
      "source": [
        "There are different types of tokenization, including:\n",
        "\n",
        "   **1- Word Tokenization:** This is the most common type of tokenization, where the text is split into words or word-like units.\n",
        "\n",
        "*Example:* the sentence \"I love programming in Python\" can be tokenized into individual words: [\"I\", \"love\", \"programming\", \"in\", \"Python\"].\n",
        "\n",
        "   **2- Sentence Tokenization:** In this type, the text is divided into sentences or sentence-like units.\n",
        "\n",
        "*Example:* the paragraph \"NLP is fascinating. It involves text analysis and language understanding.\" can be tokenized into two sentences: [\"NLP is fascinating.\", \"It involves text analysis and language understanding.\"].\n",
        "\n",
        "   **3- Subword Tokenization:** This type of tokenization breaks words into smaller subword units, which can be useful for languages with complex morphology or for machine translation tasks.\n",
        "   \n",
        "*Example:* \"unhappiness\" can be tokenized into [\"un\", \"happiness\"].\n",
        "\n",
        "   **4- Character Tokenization:**  In character tokenization, each character in the text is treated as a separate token. This level of granularity is useful for some text processing tasks.\n",
        "   \n",
        "*Example:* the word \"apple\" can be tokenized into [\"a\", \"p\", \"p\", \"l\", \"e\"].\n",
        "\n",
        "   **5- Custom Tokenization:** Depending on the specific NLP task and requirements, custom tokenization methods can be created.\n",
        "\n",
        "The choice of tokenization method depends on the task and the language being processed.\n",
        "\n",
        "Effective tokenization is crucial for various NLP tasks, including text classification, named entity recognition, machine translation, and more, as it determines how the text is divided and processed by the NLP algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b73956f",
      "metadata": {
        "id": "7b73956f"
      },
      "outputs": [],
      "source": [
        "txt_1= \"There once was a ship that put to sea. The name of the ship was the Billy O' Tea\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af56c7ac",
      "metadata": {
        "id": "af56c7ac"
      },
      "source": [
        "#### Penn Treebank tokenizer:\n",
        "This tokenizer is based on the Penn Treebank Corpus, which is a large dataset of parsed and annotated English text. It is designed to handle a wide range of English text and tokenizes words based on common conventions in English text, such as splitting on spaces and punctuation marks.\n",
        "\n",
        "The default method for the **word_tokenize** function in NLTK (Natural Language Toolkit) uses the Penn Treebank tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45071bdb",
      "metadata": {
        "id": "45071bdb"
      },
      "source": [
        "**Penn Treebank tokenization process follows these general steps:**\n",
        "\n",
        "**Whitespace Tokenization:** The text is initially split into tokens based on whitespace characters (spaces, tabs, and line breaks). This is a simple initial tokenization step.\n",
        "\n",
        "**Punctuation Handling:** After the initial whitespace tokenization, NLTK further processes the tokens by considering punctuation. Punctuation marks like periods, commas, and apostrophes are often handled in a way that separates them from adjacent words. For example, contractions like \"can't\" are split into two tokens: \"can\" and \"n't.\"\n",
        "\n",
        "**Special Cases:** NLTK may also handle specific cases, such as abbreviations or certain contractions, to ensure they are correctly tokenized. For example, \"U.S.A.\" may be tokenized as \"U.S.A\" instead of splitting it into \"U\" and \"S\" and \"A.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ccfd97",
      "metadata": {
        "id": "d7ccfd97",
        "outputId": "662c7189-bb6c-44d0-855f-29489291167a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['there', 'once', 'was', 'a', 'ship', 'that', 'put', 'to', 'sea', '.', 'the', 'name', 'of', 'the', 'ship', 'was', 'the', 'billy', 'o', \"'\", 'tea']\n"
          ]
        }
      ],
      "source": [
        "#lowercasing txt_1\n",
        "txt_1=txt_1.lower()\n",
        "#Perform word tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(txt_1)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdee2171",
      "metadata": {
        "id": "fdee2171",
        "outputId": "f83da935-ac1a-4af1-c0bd-a7bc453f3021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['there once was a ship that put to sea.', \"the name of the ship was the billy o' tea\"]\n"
          ]
        }
      ],
      "source": [
        "# Perform sentence tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(txt_1)\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b59eb5",
      "metadata": {
        "id": "c9b59eb5"
      },
      "source": [
        "## 2-3 Stopwords removal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91db85aa",
      "metadata": {
        "id": "91db85aa"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1afa91f",
      "metadata": {
        "id": "b1afa91f"
      },
      "source": [
        "Stopwords removal is a common preprocessing step in natural language processing (NLP) that involves removing common words, known as stopwords, from a text corpus. These stopwords are typically very common words in a language (e.g., \"the,\" \"and,\" \"in\") that do not carry significant meaning on their own and are often ignored or removed in text analysis to focus on more meaningful words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9492fa4c",
      "metadata": {
        "id": "9492fa4c"
      },
      "source": [
        "There are several types and methods for stopwords removal:\n",
        "\n",
        "**Default Stopwords Lists:**  Many NLP libraries, such as NLTK (Natural Language Toolkit) and spaCy, provide predefined lists of stopwords for different languages.\n",
        "\n",
        "**Custom Stopwords Lists:** Depending on the specific context of your text data, you may create custom stopwords lists by identifying words that are frequent but do not provide meaningful information in your analysis. Custom lists are often used for domain-specific text data.\n",
        "\n",
        "**Frequency-Based Removal:** Instead of using predefined lists, some methods involve removing words based on their frequency of occurrence in the text. Words that appear very frequently (e.g., in more than 90% of documents) or very infrequently may be removed.\n",
        "\n",
        "**TF-IDF Based Removal:** Term Frequency-Inverse Document Frequency (TF-IDF) is a statistical measure that evaluates the importance of words in a document relative to a corpus of documents. Stopwords can be identified by their low TF-IDF scores and removed.\n",
        "\n",
        "**Part-of-Speech Filtering:** In some cases, stopwords can be removed based on their part of speech (POS). For example, removing all words identified as \"articles\" or \"conjunctions.\"\n",
        "\n",
        "\n",
        "\n",
        "The choice of stopwords removal method depends on the specific NLP task and the characteristics of the text data. It is important to carefully consider which stopwords to remove and how it might affect the quality and meaning of your analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93aaecc1",
      "metadata": {
        "id": "93aaecc1"
      },
      "outputs": [],
      "source": [
        "#import stopword class\n",
        "from nltk.corpus import stopwords as spw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc06e05",
      "metadata": {
        "id": "9bc06e05",
        "outputId": "e54ad970-3a1b-4824-bc54-6701b84fa18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#Retrieve a list of identifiers (file IDs) for the documents or text files contained within a corpus or dataset.\n",
        "spw.fileids()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db05219",
      "metadata": {
        "id": "5db05219",
        "outputId": "270de4b5-d7d5-4e6f-a5fa-284353c8c7b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['إذ',\n",
              " 'إذا',\n",
              " 'إذما',\n",
              " 'إذن',\n",
              " 'أف',\n",
              " 'أقل',\n",
              " 'أكثر',\n",
              " 'ألا',\n",
              " 'إلا',\n",
              " 'التي',\n",
              " 'الذي',\n",
              " 'الذين',\n",
              " 'اللاتي',\n",
              " 'اللائي',\n",
              " 'اللتان',\n",
              " 'اللتيا',\n",
              " 'اللتين',\n",
              " 'اللذان',\n",
              " 'اللذين',\n",
              " 'اللواتي',\n",
              " 'إلى',\n",
              " 'إليك',\n",
              " 'إليكم',\n",
              " 'إليكما',\n",
              " 'إليكن',\n",
              " 'أم',\n",
              " 'أما',\n",
              " 'أما',\n",
              " 'إما',\n",
              " 'أن',\n",
              " 'إن',\n",
              " 'إنا',\n",
              " 'أنا',\n",
              " 'أنت',\n",
              " 'أنتم',\n",
              " 'أنتما',\n",
              " 'أنتن',\n",
              " 'إنما',\n",
              " 'إنه',\n",
              " 'أنى',\n",
              " 'أنى',\n",
              " 'آه',\n",
              " 'آها',\n",
              " 'أو',\n",
              " 'أولاء',\n",
              " 'أولئك',\n",
              " 'أوه',\n",
              " 'آي',\n",
              " 'أي',\n",
              " 'أيها',\n",
              " 'إي',\n",
              " 'أين',\n",
              " 'أين',\n",
              " 'أينما',\n",
              " 'إيه',\n",
              " 'بخ',\n",
              " 'بس',\n",
              " 'بعد',\n",
              " 'بعض',\n",
              " 'بك',\n",
              " 'بكم',\n",
              " 'بكم',\n",
              " 'بكما',\n",
              " 'بكن',\n",
              " 'بل',\n",
              " 'بلى',\n",
              " 'بما',\n",
              " 'بماذا',\n",
              " 'بمن',\n",
              " 'بنا',\n",
              " 'به',\n",
              " 'بها',\n",
              " 'بهم',\n",
              " 'بهما',\n",
              " 'بهن',\n",
              " 'بي',\n",
              " 'بين',\n",
              " 'بيد',\n",
              " 'تلك',\n",
              " 'تلكم',\n",
              " 'تلكما',\n",
              " 'ته',\n",
              " 'تي',\n",
              " 'تين',\n",
              " 'تينك',\n",
              " 'ثم',\n",
              " 'ثمة',\n",
              " 'حاشا',\n",
              " 'حبذا',\n",
              " 'حتى',\n",
              " 'حيث',\n",
              " 'حيثما',\n",
              " 'حين',\n",
              " 'خلا',\n",
              " 'دون',\n",
              " 'ذا',\n",
              " 'ذات',\n",
              " 'ذاك',\n",
              " 'ذان',\n",
              " 'ذانك',\n",
              " 'ذلك',\n",
              " 'ذلكم',\n",
              " 'ذلكما',\n",
              " 'ذلكن',\n",
              " 'ذه',\n",
              " 'ذو',\n",
              " 'ذوا',\n",
              " 'ذواتا',\n",
              " 'ذواتي',\n",
              " 'ذي',\n",
              " 'ذين',\n",
              " 'ذينك',\n",
              " 'ريث',\n",
              " 'سوف',\n",
              " 'سوى',\n",
              " 'شتان',\n",
              " 'عدا',\n",
              " 'عسى',\n",
              " 'عل',\n",
              " 'على',\n",
              " 'عليك',\n",
              " 'عليه',\n",
              " 'عما',\n",
              " 'عن',\n",
              " 'عند',\n",
              " 'غير',\n",
              " 'فإذا',\n",
              " 'فإن',\n",
              " 'فلا',\n",
              " 'فمن',\n",
              " 'في',\n",
              " 'فيم',\n",
              " 'فيما',\n",
              " 'فيه',\n",
              " 'فيها',\n",
              " 'قد',\n",
              " 'كأن',\n",
              " 'كأنما',\n",
              " 'كأي',\n",
              " 'كأين',\n",
              " 'كذا',\n",
              " 'كذلك',\n",
              " 'كل',\n",
              " 'كلا',\n",
              " 'كلاهما',\n",
              " 'كلتا',\n",
              " 'كلما',\n",
              " 'كليكما',\n",
              " 'كليهما',\n",
              " 'كم',\n",
              " 'كم',\n",
              " 'كما',\n",
              " 'كي',\n",
              " 'كيت',\n",
              " 'كيف',\n",
              " 'كيفما',\n",
              " 'لا',\n",
              " 'لاسيما',\n",
              " 'لدى',\n",
              " 'لست',\n",
              " 'لستم',\n",
              " 'لستما',\n",
              " 'لستن',\n",
              " 'لسن',\n",
              " 'لسنا',\n",
              " 'لعل',\n",
              " 'لك',\n",
              " 'لكم',\n",
              " 'لكما',\n",
              " 'لكن',\n",
              " 'لكنما',\n",
              " 'لكي',\n",
              " 'لكيلا',\n",
              " 'لم',\n",
              " 'لما',\n",
              " 'لن',\n",
              " 'لنا',\n",
              " 'له',\n",
              " 'لها',\n",
              " 'لهم',\n",
              " 'لهما',\n",
              " 'لهن',\n",
              " 'لو',\n",
              " 'لولا',\n",
              " 'لوما',\n",
              " 'لي',\n",
              " 'لئن',\n",
              " 'ليت',\n",
              " 'ليس',\n",
              " 'ليسا',\n",
              " 'ليست',\n",
              " 'ليستا',\n",
              " 'ليسوا',\n",
              " 'ما',\n",
              " 'ماذا',\n",
              " 'متى',\n",
              " 'مذ',\n",
              " 'مع',\n",
              " 'مما',\n",
              " 'ممن',\n",
              " 'من',\n",
              " 'منه',\n",
              " 'منها',\n",
              " 'منذ',\n",
              " 'مه',\n",
              " 'مهما',\n",
              " 'نحن',\n",
              " 'نحو',\n",
              " 'نعم',\n",
              " 'ها',\n",
              " 'هاتان',\n",
              " 'هاته',\n",
              " 'هاتي',\n",
              " 'هاتين',\n",
              " 'هاك',\n",
              " 'هاهنا',\n",
              " 'هذا',\n",
              " 'هذان',\n",
              " 'هذه',\n",
              " 'هذي',\n",
              " 'هذين',\n",
              " 'هكذا',\n",
              " 'هل',\n",
              " 'هلا',\n",
              " 'هم',\n",
              " 'هما',\n",
              " 'هن',\n",
              " 'هنا',\n",
              " 'هناك',\n",
              " 'هنالك',\n",
              " 'هو',\n",
              " 'هؤلاء',\n",
              " 'هي',\n",
              " 'هيا',\n",
              " 'هيت',\n",
              " 'هيهات',\n",
              " 'والذي',\n",
              " 'والذين',\n",
              " 'وإذ',\n",
              " 'وإذا',\n",
              " 'وإن',\n",
              " 'ولا',\n",
              " 'ولكن',\n",
              " 'ولو',\n",
              " 'وما',\n",
              " 'ومن',\n",
              " 'وهو',\n",
              " 'يا',\n",
              " 'أبٌ',\n",
              " 'أخٌ',\n",
              " 'حمٌ',\n",
              " 'فو',\n",
              " 'أنتِ',\n",
              " 'يناير',\n",
              " 'فبراير',\n",
              " 'مارس',\n",
              " 'أبريل',\n",
              " 'مايو',\n",
              " 'يونيو',\n",
              " 'يوليو',\n",
              " 'أغسطس',\n",
              " 'سبتمبر',\n",
              " 'أكتوبر',\n",
              " 'نوفمبر',\n",
              " 'ديسمبر',\n",
              " 'جانفي',\n",
              " 'فيفري',\n",
              " 'مارس',\n",
              " 'أفريل',\n",
              " 'ماي',\n",
              " 'جوان',\n",
              " 'جويلية',\n",
              " 'أوت',\n",
              " 'كانون',\n",
              " 'شباط',\n",
              " 'آذار',\n",
              " 'نيسان',\n",
              " 'أيار',\n",
              " 'حزيران',\n",
              " 'تموز',\n",
              " 'آب',\n",
              " 'أيلول',\n",
              " 'تشرين',\n",
              " 'دولار',\n",
              " 'دينار',\n",
              " 'ريال',\n",
              " 'درهم',\n",
              " 'ليرة',\n",
              " 'جنيه',\n",
              " 'قرش',\n",
              " 'مليم',\n",
              " 'فلس',\n",
              " 'هللة',\n",
              " 'سنتيم',\n",
              " 'يورو',\n",
              " 'ين',\n",
              " 'يوان',\n",
              " 'شيكل',\n",
              " 'واحد',\n",
              " 'اثنان',\n",
              " 'ثلاثة',\n",
              " 'أربعة',\n",
              " 'خمسة',\n",
              " 'ستة',\n",
              " 'سبعة',\n",
              " 'ثمانية',\n",
              " 'تسعة',\n",
              " 'عشرة',\n",
              " 'أحد',\n",
              " 'اثنا',\n",
              " 'اثني',\n",
              " 'إحدى',\n",
              " 'ثلاث',\n",
              " 'أربع',\n",
              " 'خمس',\n",
              " 'ست',\n",
              " 'سبع',\n",
              " 'ثماني',\n",
              " 'تسع',\n",
              " 'عشر',\n",
              " 'ثمان',\n",
              " 'سبت',\n",
              " 'أحد',\n",
              " 'اثنين',\n",
              " 'ثلاثاء',\n",
              " 'أربعاء',\n",
              " 'خميس',\n",
              " 'جمعة',\n",
              " 'أول',\n",
              " 'ثان',\n",
              " 'ثاني',\n",
              " 'ثالث',\n",
              " 'رابع',\n",
              " 'خامس',\n",
              " 'سادس',\n",
              " 'سابع',\n",
              " 'ثامن',\n",
              " 'تاسع',\n",
              " 'عاشر',\n",
              " 'حادي',\n",
              " 'أ',\n",
              " 'ب',\n",
              " 'ت',\n",
              " 'ث',\n",
              " 'ج',\n",
              " 'ح',\n",
              " 'خ',\n",
              " 'د',\n",
              " 'ذ',\n",
              " 'ر',\n",
              " 'ز',\n",
              " 'س',\n",
              " 'ش',\n",
              " 'ص',\n",
              " 'ض',\n",
              " 'ط',\n",
              " 'ظ',\n",
              " 'ع',\n",
              " 'غ',\n",
              " 'ف',\n",
              " 'ق',\n",
              " 'ك',\n",
              " 'ل',\n",
              " 'م',\n",
              " 'ن',\n",
              " 'ه',\n",
              " 'و',\n",
              " 'ي',\n",
              " 'ء',\n",
              " 'ى',\n",
              " 'آ',\n",
              " 'ؤ',\n",
              " 'ئ',\n",
              " 'أ',\n",
              " 'ة',\n",
              " 'ألف',\n",
              " 'باء',\n",
              " 'تاء',\n",
              " 'ثاء',\n",
              " 'جيم',\n",
              " 'حاء',\n",
              " 'خاء',\n",
              " 'دال',\n",
              " 'ذال',\n",
              " 'راء',\n",
              " 'زاي',\n",
              " 'سين',\n",
              " 'شين',\n",
              " 'صاد',\n",
              " 'ضاد',\n",
              " 'طاء',\n",
              " 'ظاء',\n",
              " 'عين',\n",
              " 'غين',\n",
              " 'فاء',\n",
              " 'قاف',\n",
              " 'كاف',\n",
              " 'لام',\n",
              " 'ميم',\n",
              " 'نون',\n",
              " 'هاء',\n",
              " 'واو',\n",
              " 'ياء',\n",
              " 'همزة',\n",
              " 'ي',\n",
              " 'نا',\n",
              " 'ك',\n",
              " 'كن',\n",
              " 'ه',\n",
              " 'إياه',\n",
              " 'إياها',\n",
              " 'إياهما',\n",
              " 'إياهم',\n",
              " 'إياهن',\n",
              " 'إياك',\n",
              " 'إياكما',\n",
              " 'إياكم',\n",
              " 'إياك',\n",
              " 'إياكن',\n",
              " 'إياي',\n",
              " 'إيانا',\n",
              " 'أولالك',\n",
              " 'تانِ',\n",
              " 'تانِك',\n",
              " 'تِه',\n",
              " 'تِي',\n",
              " 'تَيْنِ',\n",
              " 'ثمّ',\n",
              " 'ثمّة',\n",
              " 'ذانِ',\n",
              " 'ذِه',\n",
              " 'ذِي',\n",
              " 'ذَيْنِ',\n",
              " 'هَؤلاء',\n",
              " 'هَاتانِ',\n",
              " 'هَاتِه',\n",
              " 'هَاتِي',\n",
              " 'هَاتَيْنِ',\n",
              " 'هَذا',\n",
              " 'هَذانِ',\n",
              " 'هَذِه',\n",
              " 'هَذِي',\n",
              " 'هَذَيْنِ',\n",
              " 'الألى',\n",
              " 'الألاء',\n",
              " 'أل',\n",
              " 'أنّى',\n",
              " 'أيّ',\n",
              " 'ّأيّان',\n",
              " 'أنّى',\n",
              " 'أيّ',\n",
              " 'ّأيّان',\n",
              " 'ذيت',\n",
              " 'كأيّ',\n",
              " 'كأيّن',\n",
              " 'بضع',\n",
              " 'فلان',\n",
              " 'وا',\n",
              " 'آمينَ',\n",
              " 'آهِ',\n",
              " 'آهٍ',\n",
              " 'آهاً',\n",
              " 'أُفٍّ',\n",
              " 'أُفٍّ',\n",
              " 'أفٍّ',\n",
              " 'أمامك',\n",
              " 'أمامكَ',\n",
              " 'أوّهْ',\n",
              " 'إلَيْكَ',\n",
              " 'إلَيْكَ',\n",
              " 'إليكَ',\n",
              " 'إليكنّ',\n",
              " 'إيهٍ',\n",
              " 'بخٍ',\n",
              " 'بسّ',\n",
              " 'بَسْ',\n",
              " 'بطآن',\n",
              " 'بَلْهَ',\n",
              " 'حاي',\n",
              " 'حَذارِ',\n",
              " 'حيَّ',\n",
              " 'حيَّ',\n",
              " 'دونك',\n",
              " 'رويدك',\n",
              " 'سرعان',\n",
              " 'شتانَ',\n",
              " 'شَتَّانَ',\n",
              " 'صهْ',\n",
              " 'صهٍ',\n",
              " 'طاق',\n",
              " 'طَق',\n",
              " 'عَدَسْ',\n",
              " 'كِخ',\n",
              " 'مكانَك',\n",
              " 'مكانَك',\n",
              " 'مكانَك',\n",
              " 'مكانكم',\n",
              " 'مكانكما',\n",
              " 'مكانكنّ',\n",
              " 'نَخْ',\n",
              " 'هاكَ',\n",
              " 'هَجْ',\n",
              " 'هلم',\n",
              " 'هيّا',\n",
              " 'هَيْهات',\n",
              " 'وا',\n",
              " 'واهاً',\n",
              " 'وراءَك',\n",
              " 'وُشْكَانَ',\n",
              " 'وَيْ',\n",
              " 'يفعلان',\n",
              " 'تفعلان',\n",
              " 'يفعلون',\n",
              " 'تفعلون',\n",
              " 'تفعلين',\n",
              " 'اتخذ',\n",
              " 'ألفى',\n",
              " 'تخذ',\n",
              " 'ترك',\n",
              " 'تعلَّم',\n",
              " 'جعل',\n",
              " 'حجا',\n",
              " 'حبيب',\n",
              " 'خال',\n",
              " 'حسب',\n",
              " 'خال',\n",
              " 'درى',\n",
              " 'رأى',\n",
              " 'زعم',\n",
              " 'صبر',\n",
              " 'ظنَّ',\n",
              " 'عدَّ',\n",
              " 'علم',\n",
              " 'غادر',\n",
              " 'ذهب',\n",
              " 'وجد',\n",
              " 'ورد',\n",
              " 'وهب',\n",
              " 'أسكن',\n",
              " 'أطعم',\n",
              " 'أعطى',\n",
              " 'رزق',\n",
              " 'زود',\n",
              " 'سقى',\n",
              " 'كسا',\n",
              " 'أخبر',\n",
              " 'أرى',\n",
              " 'أعلم',\n",
              " 'أنبأ',\n",
              " 'حدَث',\n",
              " 'خبَّر',\n",
              " 'نبَّا',\n",
              " 'أفعل به',\n",
              " 'ما أفعله',\n",
              " 'بئس',\n",
              " 'ساء',\n",
              " 'طالما',\n",
              " 'قلما',\n",
              " 'لات',\n",
              " 'لكنَّ',\n",
              " 'ءَ',\n",
              " 'أجل',\n",
              " 'إذاً',\n",
              " 'أمّا',\n",
              " 'إمّا',\n",
              " 'إنَّ',\n",
              " 'أنًّ',\n",
              " 'أى',\n",
              " 'إى',\n",
              " 'أيا',\n",
              " 'ب',\n",
              " 'ثمَّ',\n",
              " 'جلل',\n",
              " 'جير',\n",
              " 'رُبَّ',\n",
              " 'س',\n",
              " 'علًّ',\n",
              " 'ف',\n",
              " 'كأنّ',\n",
              " 'كلَّا',\n",
              " 'كى',\n",
              " 'ل',\n",
              " 'لات',\n",
              " 'لعلَّ',\n",
              " 'لكنَّ',\n",
              " 'لكنَّ',\n",
              " 'م',\n",
              " 'نَّ',\n",
              " 'هلّا',\n",
              " 'وا',\n",
              " 'أل',\n",
              " 'إلّا',\n",
              " 'ت',\n",
              " 'ك',\n",
              " 'لمّا',\n",
              " 'ن',\n",
              " 'ه',\n",
              " 'و',\n",
              " 'ا',\n",
              " 'ي',\n",
              " 'تجاه',\n",
              " 'تلقاء',\n",
              " 'جميع',\n",
              " 'حسب',\n",
              " 'سبحان',\n",
              " 'شبه',\n",
              " 'لعمر',\n",
              " 'مثل',\n",
              " 'معاذ',\n",
              " 'أبو',\n",
              " 'أخو',\n",
              " 'حمو',\n",
              " 'فو',\n",
              " 'مئة',\n",
              " 'مئتان',\n",
              " 'ثلاثمئة',\n",
              " 'أربعمئة',\n",
              " 'خمسمئة',\n",
              " 'ستمئة',\n",
              " 'سبعمئة',\n",
              " 'ثمنمئة',\n",
              " 'تسعمئة',\n",
              " 'مائة',\n",
              " 'ثلاثمائة',\n",
              " 'أربعمائة',\n",
              " 'خمسمائة',\n",
              " 'ستمائة',\n",
              " 'سبعمائة',\n",
              " 'ثمانمئة',\n",
              " 'تسعمائة',\n",
              " 'عشرون',\n",
              " 'ثلاثون',\n",
              " 'اربعون',\n",
              " 'خمسون',\n",
              " 'ستون',\n",
              " 'سبعون',\n",
              " 'ثمانون',\n",
              " 'تسعون',\n",
              " 'عشرين',\n",
              " 'ثلاثين',\n",
              " 'اربعين',\n",
              " 'خمسين',\n",
              " 'ستين',\n",
              " 'سبعين',\n",
              " 'ثمانين',\n",
              " 'تسعين',\n",
              " 'بضع',\n",
              " 'نيف',\n",
              " 'أجمع',\n",
              " 'جميع',\n",
              " 'عامة',\n",
              " 'عين',\n",
              " 'نفس',\n",
              " 'لا سيما',\n",
              " 'أصلا',\n",
              " 'أهلا',\n",
              " 'أيضا',\n",
              " 'بؤسا',\n",
              " 'بعدا',\n",
              " 'بغتة',\n",
              " 'تعسا',\n",
              " 'حقا',\n",
              " 'حمدا',\n",
              " 'خلافا',\n",
              " 'خاصة',\n",
              " 'دواليك',\n",
              " 'سحقا',\n",
              " 'سرا',\n",
              " 'سمعا',\n",
              " 'صبرا',\n",
              " 'صدقا',\n",
              " 'صراحة',\n",
              " 'طرا',\n",
              " 'عجبا',\n",
              " 'عيانا',\n",
              " 'غالبا',\n",
              " 'فرادى',\n",
              " 'فضلا',\n",
              " 'قاطبة',\n",
              " 'كثيرا',\n",
              " 'لبيك',\n",
              " 'معاذ',\n",
              " 'أبدا',\n",
              " 'إزاء',\n",
              " 'أصلا',\n",
              " 'الآن',\n",
              " 'أمد',\n",
              " 'أمس',\n",
              " 'آنفا',\n",
              " 'آناء',\n",
              " 'أنّى',\n",
              " 'أول',\n",
              " 'أيّان',\n",
              " 'تارة',\n",
              " 'ثمّ',\n",
              " 'ثمّة',\n",
              " 'حقا',\n",
              " 'صباح',\n",
              " 'مساء',\n",
              " 'ضحوة',\n",
              " 'عوض',\n",
              " 'غدا',\n",
              " 'غداة',\n",
              " 'قطّ',\n",
              " 'كلّما',\n",
              " 'لدن',\n",
              " 'لمّا',\n",
              " 'مرّة',\n",
              " 'قبل',\n",
              " 'خلف',\n",
              " 'أمام',\n",
              " 'فوق',\n",
              " 'تحت',\n",
              " 'يمين',\n",
              " 'شمال',\n",
              " 'ارتدّ',\n",
              " 'استحال',\n",
              " 'أصبح',\n",
              " 'أضحى',\n",
              " 'آض',\n",
              " 'أمسى',\n",
              " 'انقلب',\n",
              " 'بات',\n",
              " 'تبدّل',\n",
              " 'تحوّل',\n",
              " 'حار',\n",
              " 'رجع',\n",
              " 'راح',\n",
              " 'صار',\n",
              " 'ظلّ',\n",
              " 'عاد',\n",
              " 'غدا',\n",
              " 'كان',\n",
              " 'ما انفك',\n",
              " 'ما برح',\n",
              " 'مادام',\n",
              " 'مازال',\n",
              " 'مافتئ',\n",
              " 'ابتدأ',\n",
              " 'أخذ',\n",
              " 'اخلولق',\n",
              " 'أقبل',\n",
              " 'انبرى',\n",
              " 'أنشأ',\n",
              " 'أوشك',\n",
              " 'جعل',\n",
              " 'حرى',\n",
              " 'شرع',\n",
              " 'طفق',\n",
              " 'علق',\n",
              " 'قام',\n",
              " 'كرب',\n",
              " 'كاد',\n",
              " 'هبّ']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#get the arabic stopwords\n",
        "\n",
        "spw.words('arabic')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56a0ca1",
      "metadata": {
        "id": "e56a0ca1",
        "outputId": "97776408-c64c-4cde-8637-3d41d2831a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#get the english stopwords\n",
        "spw.words('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73a0c4d",
      "metadata": {
        "id": "f73a0c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9308b15-91ef-4ba0-969f-237c5821f4ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "removed ['the', 'on', 'the', 'not', 'a', 'to', 'be', 'a', 'of', 'and', 'it', 'i', 'the']\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "text_2= \"The snow glows white on the mountain tonight, Not a footprint to be seen. A kingdom of isolation, And it looks like I\\'m the queen\"\n",
        "# 1/ lowercasing\n",
        "text_2 = text_2.lower()\n",
        "# 2/ word tokenization\n",
        "words = word_tokenize(text_2)\n",
        "words\n",
        "# 3/ stopword removal and display clean text\n",
        "stop_words = set(spw.words('english'))\n",
        "\n",
        "clean_words = [word for word in words if word not in stop_words]\n",
        "clean_words\n",
        "\n",
        "# 4/ display removed stopwords\n",
        "\n",
        "removed = [ w for w in words if w in stop_words]\n",
        "print('removed', removed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72836367",
      "metadata": {
        "id": "72836367",
        "outputId": "3354d8fe-474c-4620-ac37-1d4be1dd4fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text:\n",
            "the snow glows white on the mountain tonight, not a footprint to be seen. a kingdom of isolation, and it looks like i'm the queen\n",
            "\n",
            "Word Tokenization:\n",
            "['the', 'snow', 'glows', 'white', 'on', 'the', 'mountain', 'tonight', ',', 'not', 'a', 'footprint', 'to', 'be', 'seen', '.', 'a', 'kingdom', 'of', 'isolation', ',', 'and', 'it', 'looks', 'like', 'i', \"'m\", 'the', 'queen']\n"
          ]
        }
      ],
      "source": [
        "# 1/ lowercasing\n",
        "# 2/ word tokenization\n",
        "# 1. Lowercasing\n",
        "text_lower = text_2.lower()\n",
        "print(\"Lowercased Text:\")\n",
        "print(text_lower)\n",
        "\n",
        "# 2. Word Tokenization\n",
        "words = word_tokenize(text_lower)\n",
        "print(\"\\nWord Tokenization:\")\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd469b0",
      "metadata": {
        "id": "7cd469b0"
      },
      "outputs": [],
      "source": [
        "# 3/ stopword removal and display clean text\n",
        "\n",
        "None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3eaca6",
      "metadata": {
        "id": "bb3eaca6"
      },
      "outputs": [],
      "source": [
        "# 4/ display removed stopwords\n",
        "\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a59871",
      "metadata": {
        "id": "27a59871"
      },
      "source": [
        "## 2-4 Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529b9f8b",
      "metadata": {
        "id": "529b9f8b"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f9029c5",
      "metadata": {
        "id": "1f9029c5"
      },
      "source": [
        "Stemming in natural language processing is the process of reducing words to their root or base form. The goal of stemming is to remove suffixes (and sometimes prefixes) from words so that similar words with the same root are treated as the same word, regardless of their inflections or variations.\n",
        "\n",
        "\n",
        "It's essential to note that stemming algorithms are heuristic and may not always produce perfect results, as they can sometimes generate non-words or incorrect stems. Nonetheless, stemming is a valuable technique for text processing and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0105ca",
      "metadata": {
        "id": "aa0105ca"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b59fdd",
      "metadata": {
        "id": "91b59fdd",
        "outputId": "051223a3-2265-495f-a2fc-3da5841a8ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n"
          ]
        }
      ],
      "source": [
        "# Porter Stemmer\n",
        "\n",
        "ps= nltk.PorterStemmer()\n",
        "print(ps.stem('waiting')) #ken jidher mtaa kilma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42c9a57",
      "metadata": {
        "id": "b42c9a57",
        "outputId": "e9ed9653-f845-45e7-b40f-19c2512c456c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n",
            "wait\n",
            "wait\n"
          ]
        }
      ],
      "source": [
        "words=[\"waited\",\"waiting\",\"waits\"]\n",
        "for w in words:\n",
        "  print(ps.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc9669d",
      "metadata": {
        "id": "ffc9669d",
        "outputId": "735b8d12-4cc8-4a0e-b2fa-bfb1690dae08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "troubl\n"
          ]
        }
      ],
      "source": [
        "# heuristic! might do mistakes\n",
        "print(ps.stem('trouble')) #pour diminuer la len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a081fe68",
      "metadata": {
        "id": "a081fe68"
      },
      "source": [
        "## 2-5 Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3ea811",
      "metadata": {
        "id": "ed3ea811"
      },
      "source": [
        "Lemmatization is a natural language processing technique that involves reducing words to their base or root form, known as a lemma. Unlike stemming, which uses heuristic rules to remove suffixes from words, lemmatization aims to find the actual dictionary form of a word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce46b073",
      "metadata": {
        "id": "ce46b073"
      },
      "source": [
        "For example, the lemma of the word \"better\" is \"good,\" and the lemma of \"jumps\" is \"jump.\"\n",
        "\n",
        " Lemmatization considers word context and part-of-speech information to determine the appropriate lemma. It helps in achieving more accurate and meaningful results in text analysis, as it produces valid words that can be found in dictionaries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247268ec",
      "metadata": {
        "id": "247268ec"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01061d31",
      "metadata": {
        "id": "01061d31"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd76b903",
      "metadata": {
        "id": "fd76b903"
      },
      "source": [
        "#### Why do we need Stemming if we have Lemmatization ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f263a0d5",
      "metadata": {
        "id": "f263a0d5"
      },
      "source": [
        "1.Stemming is generally faster and computationally less expensive than lemmatization. Lemmatization requires dictionary lookups and part-of-speech tagging, which can be more time-consuming.\n",
        "\n",
        "**--> Speed and Efficiency**\n",
        "\n",
        "2.Stemming rules are simpler and easier to implement than lemmatization algorithms, which often involve more complex linguistic analysis.\n",
        "\n",
        "**--> Simplicity**\n",
        "\n",
        "3.Stemming can help in information **retrieval tasks** where you want to match multiple word forms to a common root. For example, if you search for \"running,\" stemming could match it to documents containing \"run\" or \"runner.\" This can be useful in search engines and document retrieval systems.\n",
        "\n",
        "4.Stemming can help reduce the dimensionality of text data. By converting words to their root forms, you reduce the number of unique words in your dataset, which can be advantageous for certain machine learning models, especially when you have limited data.\n",
        "**--> Reducing Dimensionality**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427f241b",
      "metadata": {
        "id": "427f241b"
      },
      "outputs": [],
      "source": [
        "#import WordNetLemmatizer #lemmatizer men plusieur yrajaa le singulier\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4df6c79",
      "metadata": {
        "id": "b4df6c79",
        "outputId": "d3607cec-6c34-4b26-9a4a-5f713169f717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trouble\n",
            "wait\n"
          ]
        }
      ],
      "source": [
        "lem = WordNetLemmatizer()\n",
        "print(lem.lemmatize('trouble'))\n",
        "print(lem.lemmatize('waits'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0ab993",
      "metadata": {
        "id": "9d0ab993",
        "outputId": "2df6561f-d780-4559-f6a8-40a43099828d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "waiting\n"
          ]
        }
      ],
      "source": [
        "print(lem.lemmatize('waiting'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afd3d3a5",
      "metadata": {
        "id": "afd3d3a5"
      },
      "source": [
        "The output of *lem.lemmatize('waiting')* doesn't give \"wait\" because the lemmatize function from the NLTK library, by default, assumes that the input word is a noun.\n",
        "\n",
        "In English, the base form of verbs is typically the infinitive form (e.g., \"to wait\"), and lemmatization aims to convert words to their base or dictionary forms.\n",
        "\n",
        "If you want to lemmatize a verb like \"waiting\" to \"wait,\" you need to specify the part of speech (POS) tag explicitly because lemmatization can be different for nouns, verbs, adjectives, etc. You can do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2cee61b",
      "metadata": {
        "id": "a2cee61b",
        "outputId": "dfd2ef7d-ddce-4abf-d295-d02012f4c7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n"
          ]
        }
      ],
      "source": [
        "# by part of speech\n",
        "print(lem.lemmatize('waiting', pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c077107f",
      "metadata": {
        "scrolled": true,
        "id": "c077107f",
        "outputId": "d79d94d9-aa59-48ee-939f-9b62f4dfcb88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ff257c",
      "metadata": {
        "id": "d5ff257c"
      },
      "source": [
        "💡💡💡💡**Key Features of WordNet**\n",
        "\n",
        "**Definition of WordNet**: WordNet is a large lexical database of English, organized into sets of synonyms called synsets. Each synset represents a distinct concept and includes words that are interchangeable in some context. WordNet provides a rich network of semantic relationships between words, such as synonyms, antonyms, hypernyms (generalizations), and hyponyms (specialized terms).\n",
        "\n",
        "**1- Synsets:**\n",
        "\n",
        "A synset is a set of synonyms that express a distinct concept. For example, the synset for the word \"car\" might include words like \"automobile,\" \"auto,\" and \"machine.\"\n",
        "\n",
        "**2- Semantic Relationships:**\n",
        "\n",
        "**Hyponyms:** More specific terms. For example, \"rose\" is a hyponym of \"flower.\"\n",
        "\n",
        "**Hypernyms:** More general terms. For example, \"flower\" is a hypernym of \"rose.\"\n",
        "\n",
        "**Antonyms:** Words with opposite meanings. For example, \"happy\" and \"sad\" are antonyms.\n",
        "\n",
        "**3-Parts of Speech:**\n",
        "\n",
        "Words are organized by parts of speech: nouns, verbs, adjectives, and adverbs. Each part of speech has its own set of synsets and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53471f72",
      "metadata": {
        "id": "53471f72"
      },
      "source": [
        "# Example:\n",
        "\n",
        "Here is a sample text\n",
        "\n",
        "\"The cats are running and the dogs are barking loudly.\"\n",
        "\n",
        "1- Tokenize the text into words\n",
        "\n",
        "2- Lemmatize each word and join them back into a sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad571e2",
      "metadata": {
        "id": "dad571e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161ea669-cc87-4fc8-8386-827b04ef30ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat are running and the dog are barking loudly .\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the WordNet lemmatizer\n",
        "lem = WordNetLemmatizer()\n",
        "\n",
        "# Sample text\n",
        "text= \"The cats are running and the dogs are barking loudly.\"\n",
        "\n",
        "\n",
        "# Tokenize the text into words\n",
        "words= word_tokenize(text)\n",
        "\n",
        "# Lemmatize each word and join them back into a sentence\n",
        "\n",
        "lemmatized_text=' '.join([lem.lemmatize(word) for word in words])\n",
        "\n",
        "print(lemmatized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0f82b4",
      "metadata": {
        "id": "2d0f82b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc815f2-8da8-4da5-9225-0b4c460330d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cat',\n",
              " 'are',\n",
              " 'running',\n",
              " 'and',\n",
              " 'the',\n",
              " 'dog',\n",
              " 'are',\n",
              " 'barking',\n",
              " 'loudly',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "lemmatized_words = [lem.lemmatize(word) for word in words]\n",
        "lemmatized_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5772f18e",
      "metadata": {
        "id": "5772f18e"
      },
      "source": [
        "# Example :\n",
        "Remove symbols from text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cb1e753",
      "metadata": {
        "id": "7cb1e753",
        "outputId": "f659280b-d480-46bf-8dbf-fa5dfd54955f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'how', 'are', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Here is an example\n",
        "text_3=\"Hello 123 # how $ are you? \"\n",
        "# 1- Lowercase\n",
        "text_3 = text_3.lower()\n",
        " # 2- Tokenize\n",
        "words= word_tokenize(text_3)\n",
        "# 3- Filter text by removing symbols (use isalpha())\n",
        "filtered_text_3 = [w for w in words if w.isalpha()]\n",
        "# 4- display output\n",
        "filtered_text_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4419399f",
      "metadata": {
        "id": "4419399f"
      },
      "source": [
        "## 2-6 Spell checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c28068f",
      "metadata": {
        "id": "1c28068f",
        "outputId": "1d275d9b-ee39-4239-dd10-964691f403f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/622.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=5b7e9a3faf5014f3dffc1173c5f7509518a0df8f87c2027d9bd9c4fc7e116947\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f92048",
      "metadata": {
        "id": "63f92048",
        "outputId": "3e397b21-7433-4cb7-f0cb-d132a117712a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This world is magical'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# spell checker using class Speller #spell pour corriger # tu fais l'entrer ton rapport par exemple :) ! yarjaa lel dictionnaire\n",
        "from autocorrect import Speller\n",
        "spell = Speller(lang= 'en')\n",
        "text_4= \"This wrld is magcal\"\n",
        "tokens= word_tokenize(text_4)\n",
        "correct_text = ' '.join([spell(w) for w in tokens])\n",
        "correct_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5b886e",
      "metadata": {
        "id": "6c5b886e"
      },
      "source": [
        "## 3- Exercice:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdbe5314",
      "metadata": {
        "id": "cdbe5314"
      },
      "source": [
        "#### case study:\n",
        "\n",
        "Create a function named *preprocessing* that reads the \"pride_and_prejudice.txt\" file and performs the standard preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da389b3a",
      "metadata": {
        "id": "da389b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526d16f3-e9c0-4b93-8650-344c6f891aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barron', 'book', 'note', 'jane', 'austen', 'pride', 'prejudic', 'jane', 'austen', 'author', 'time', 'jane', 'austen', 'countri', 'parson', 'daughter', 'live', 'life', 'tini', 'english', 'villag', 'began', 'write', 'first', 'novel', 'sens', 'sensibl', 'still', 'late', 'teen', 'wrote', 'origin', 'version', 'second', 'famou', 'novel', 'pride', 'prejudic', 'origin', 'entitl', 'first', 'impress', 'yet', 'twentyon', 'time', 'never', 'away', 'home', 'except', 'year']\n"
          ]
        }
      ],
      "source": [
        "def preprocessing(filename):\n",
        "  f= open(filename, encoding=\"utf8\")\n",
        "  text= f.read()\n",
        "  text_l= text.lower()\n",
        "  tokens = nltk.word_tokenize(text_l)\n",
        "  filetered_tokens = [word for word in tokens if word.isalpha()]\n",
        "  stopw_text = [w for w in filetered_tokens if w not in spw]\n",
        "  return stopw_text\n",
        "file_path = \"/content/PrideandPrejudice.txt\"\n",
        "processed_words = preprocessing(file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6073181",
      "metadata": {
        "scrolled": true,
        "id": "f6073181"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1926de7b",
      "metadata": {
        "id": "1926de7b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6d5e47f6",
      "metadata": {
        "id": "6d5e47f6"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}